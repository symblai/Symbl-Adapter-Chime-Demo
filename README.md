# Symbl Conversational AI Adapter for Chime SDK Demo App

Application that demonstrates Symbl's Conversational AI Adapter with Chime SDK capabilities and easy integration.

## Features


### Initialization

The Symbl adapter should be initialized after connecting to your Chime video conference and your access token is generated by your backend service. For instructions on how to do this please see here.

Once your Symbl Access Token is retrieved, you can set it by setting the static property `ACCESS_TOKEN` on the Symbl class.
```
Symbl.ACCESS_TOKEN = joinInfo.Symbl.accessToken;
```

Once your access token is set you can call the constructor as shown below.

```
/**
@param {object} chime - chime instance
    @property {object} configuration : {
        @property {object} credentials: {
            ...
            @property {string} attendeeId - Client attendee id
            @property {string} externalUserId - User name
            ...
        },
        @property {string} meetingId -- UUID of the Chime Meeting
    },
    @property {string} meeting - Meeting name
}
*/
const symbl = new Symbl({
    configuration: {
        credentials: {
            attendeeId: chime.credentials.attendeeId,
            externalUserId: chime.credentials.externalUserId,
        },
        meetingId: "acbd0689-9b84-42f7-b8b8-9bc3aa7b057a".
    },
    meeting: 'My Meeting Name'
});
```

### Realtime Closed Captioning

Realtime closed captioning can easily be added to your Chime SDK video chat application by creating a handler with 3 callback functions:
- `onClosedCaptioningToggled` - Will be called whenever closed captioning is toggled on or off.
- `subtitleCreated` - Called whenever speech is first detected and a new captioning object is created.
- `subtitleUpdated` - Called when speech is subsequently detected

The handler can be added by calling the `subscribeToCaptioningEvents` function of your Symbl instance.


```
const captioningHandler = {
    onClosedCaptioningToggled: (ccEnabled: boolean) => {
        // Implement
    },
    subtitleCreated: (subtitle: Caption) => {
        console.warn('Subtitle created', subtitle);
        // Retrieve the video element that you wish to add the subtitle tracks to.
        const activeVideoElement = getActiveVideoElement() as HTMLVideoElement;
        if (activeVideoElement) {
            subtitle.setVideoElement(activeVideoElement);
        }
    },
    subtitleUpdated: (subtitle: Caption) => {
        const activeVideoElement = getActiveVideoElement() as HTMLVideoElement;
        // Check if the video element is set correctly
        if (!subtitle.videoElement && activeVideoElement) {
            subtitle.setVideoElement(activeVideoElement);
        }
        if (activeVideoElement && subtitle.videoElement !== activeVideoElement) {
            console.log('Active video element changed', activeVideoElement);
            subtitle.setVideoElement(activeVideoElement);
        }
    },
};
symbl.subscribeToCaptioningEvents(captioningHandler);
```

Setting the video element that subtitles will be superimposed over should be done by calling the `setVideoElement` function on the `Caption` class.

If your video chat application has alternating primary video tiles, this can be used to change which element is active.


### Realtime Insights

Realtime insights are generated as Symbl processes the conversation in your video chat platform.

The Symbl adapter exposes a function, `subscribeToInsightEvents`, that takes a handler with a function called `onInsightsCreated`.
Insights are enabled by default, or by passing a property `insightsEnabled` in the `config` parameter of the `Symbl` constructor.

```
new Symbl(chimeConfiguration, {insightsEnabled: true});
```

By creating a handler and passing it into the `subscribeToInsightEvents` function, we can create a default element or use the data included in the `Insight` object returned in the handlers callback.

```
const insightHandler = {
    onInsightCreated: (insight: Insight) => {
        // Creates a predesigned insight widget;
        const element = insight.createElement();
        // Customize any styling
        element.classList.add('mx-auto');
        element.style.width = '98%';
        // Get container you wish to add insights to.
        const insightContainer = document.getElementById('receive-insight');
        // Call add on the insight object to add it to DIV
        insight.add(insightContainer);
    }
};
// Subscribe to realtime insight events using the handler created above
this.symbl.subscribeToInsightEvents(insightHandler);
```

## Prerequisites
You must have the following installed:

* [Node.js v10+](https://nodejs.org/en/download/)
* npm 6.11 or higher

* [Install the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv1.html)
* [Install the AWS SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html)



## Installation

Make sure you have Node.js version 10 and higher.
To add the Amazon Chime SDK for JavaScript into an existing application,
install the package directly from npm:

```
npm install
cd demos/browser
npm install
cd ../serverless
npm install

```

## Set Up for Symbl

#### Symbl Credentials
* Create an account in the [Symbl Console](https://platform.symbl.ai) if you don't have one already.
* After you login, you will find your appId and appSecret on the home page.
* Create a `.env` file in `demos/browser` and `demos/serverless/src` that includes your appId and appSecret as shown below.

```.env
SYMBL_APP_ID=<xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx>
SYMBL_APP_SECRET=<xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx>
```

The App ID and App Secret are used to authenticate your session with Symbl by generating an access token.
Your App ID and Secret should not be shared or posted publicly.


## Local Demo

This demo shows how one might implement Symbl Conversational AI Adapter for Amazon Chime SDK to build meeting applications with realtime transcription and insights using Symbl's [Realtime Websockets API](https://docs.symbl.ai/#real-time-websocket-api).

#### Prerequisites - Local

To build, test, and run demos from source you will need:

- Node 10 or higher
- npm 6.11 or higher


### Serverless Deployment



## Run deployment script

Make sure you have built the browser application by running
```
cd demos/browser
npm run build
```

The following will create a CloudFormation stack containing a Lambda and
API Gateway deployment that runs the `meetingV2` demo.

```
npm run deploy -- -r us-east-1 -b <my-bucket> -s <my-stack-name> -a meetingV2
```
This script will create an S3 bucket and CloudFormation stack
with Lambda and API Gateway resources required to run the demo. After the script
finishes, it will output a URL that can be opened in a browser.

### Running the browser demos with a local server

1. Navigate to the `demos/browser` folder: `cd demos/browser`

2. Start the demo application: `npm run start`

3. Open http://localhost:8080 in your browser.

### Running

Browser demo applications are located in the `app` folder. Current demos are:

To run the Symbl Conversation AI demo application use:

```
npm run start
```

After running `start` the first time, you can speed things up on subsequent iterations by using `start:fast`, e.g.

```
npm run start:fast
```
